from typing import Dict, Optional, List, Tuple
import logging
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from app.config import settings
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import asyncio

logger = logging.getLogger(__name__)

class CategoryPartitionedRouter:
    """
    Advanced Hybrid Router v·ªõi category-based data partitioning
    
    Lu·ªìng ho·∫°t ƒë·ªông:
    1. LLM Classification ƒë·ªÉ x√°c ƒë·ªãnh category
    2. N·∫øu category = "KH√ÅC" ‚Üí RAG_CHAT (b·ªè qua vector)
    3. N·∫øu category h·ª£p l·ªá ‚Üí Vector search CH·ªà trong partition t∆∞∆°ng ·ª©ng
    4. T√¨m similarity trong partition, n·∫øu ƒë·ªß cao ‚Üí tr·∫£ answer, n·∫øu kh√¥ng ‚Üí RAG_CHAT
    """
    
    def __init__(self, vector_store=None, use_categorized_data=True):
        # Initialize LLM cho classification
        self.llm = ChatOpenAI(
            openai_api_key=settings.openai_api_key,
            model_name="gpt-4o-mini",
            temperature=0
        )
        
        # Initialize embeddings cho vector search
        self.embeddings = OpenAIEmbeddings(
            openai_api_key=settings.openai_api_key,
            model="text-embedding-ada-002"
        )
        
        # Use existing vector store (Qdrant) instead of local cache
        self.vector_store = vector_store
        if not self.vector_store:
            raise ValueError("Vector store (Qdrant) is required for CategoryPartitionedRouter")
        
        # Load data for category information only (kh√¥ng c·∫ßn embed l·∫°i)
        self.use_categorized_data = use_categorized_data
        self.data = self._load_data()
        
        # Similarity threshold cho vector search
        self.similarity_threshold = 0.8
        
        # ƒê·ªãnh nghƒ©a c√°c category h·ª£p l·ªá
        self.valid_categories = [
            "H·ªåC PH√ç", "NG√ÄNH H·ªåC", "QUY CH·∫æ THI", "ƒêI·ªÇM S·ªê", 
            "D·ªäCH V·ª§ SINH VI√äN", "C∆† S·ªû V·∫¨T CH·∫§T", "CH∆Ø∆†NG TR√åNH H·ªåC"
        ]
        
        # Cache cho classification results ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô v√† consistency
        self.classification_cache = {}  # {query_hash: classification_result}
        
        # Cache cho vector search results (optional)
        self.vector_search_cache = {}  # {query_hash: vector_search_result}
        self.cache_expiry_time = 3600  # 1 hour cache expiry
        
        print(f"CategoryPartitionedRouter initialized with {len(self.data)} questions")
        print(f"Valid categories: {self.valid_categories}")
        print(f"‚úÖ Using existing Qdrant vector store for category-partitioned search")
        
        # Hi·ªÉn th·ªã th·ªëng k√™ category
        if 'category' in self.data.columns:
            category_stats = self.data['category'].value_counts()
            print(f"üìä Category distribution:")
            for cat, count in category_stats.items():
                print(f"   {cat}: {count} questions")
        else:
            print("‚ö†Ô∏è  No category column found - will categorize on demand")
    
    def _load_data(self):
        """Load data v·ªõi ∆∞u ti√™n file c√≥ category"""
        try:
            if self.use_categorized_data:
                # Th·ª≠ load file ƒë√£ c√≥ category tr∆∞·ªõc
                try:
                    df = pd.read_excel('app/data_test_with_categories.xlsx')
                    print("‚úÖ Loaded categorized data file")
                    return df
                except FileNotFoundError:
                    print("‚ö†Ô∏è  Categorized data file not found, falling back to original")
            
            # Fallback sang file g·ªëc
            df = pd.read_excel('app/data_test.xlsx')
            print("‚úÖ Loaded original data file")
            return df
            
        except Exception as e:
            print(f"‚ùå Error loading data: {e}")
            raise

    async def _classify_query_category(self, query: str) -> Dict:
        """B∆∞·ªõc 1: Ph√¢n lo·∫°i category b·∫±ng LLM v·ªõi Prompt Engineering cao c·∫•p"""
        
        # üöÄ CACHE CHECK ƒë·ªÉ ƒë·∫£m b·∫£o consistency
        import hashlib
        query_hash = hashlib.md5(query.lower().strip().encode()).hexdigest()
        
        if query_hash in self.classification_cache:
            cached_result = self.classification_cache[query_hash]
            print(f"üéØ Using cached classification: {cached_result['category']}")
            return cached_result
        
        system_prompt = f"""B·∫°n l√† chuy√™n gia ph√¢n lo·∫°i c√¢u h·ªèi v·ªÅ tr∆∞·ªùng ƒë·∫°i h·ªçc v·ªõi ƒë·ªô ch√≠nh x√°c 100%. Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n lo·∫°i c√¢u h·ªèi v√†o ƒê√öNG M·ªòT trong c√°c danh m·ª•c sau:

üìö DANH M·ª§C C·ª§ TH·ªÇ (7 lo·∫°i):
1. H·ªåC PH√ç - T·∫•t c·∫£ v·ªÅ ti·ªÅn b·∫°c:
   ‚Ä¢ H·ªçc ph√≠, chi ph√≠ h·ªçc t·∫≠p, ti·ªÅn ƒë√≥ng h·ªçc
   ‚Ä¢ Mi·ªÖn gi·∫£m h·ªçc ph√≠, h·ªçc b·ªïng
   ‚Ä¢ T·ª´ kh√≥a: "h·ªçc ph√≠", "chi ph√≠", "ti·ªÅn", "ƒë√≥ng h·ªçc", "mi·ªÖn gi·∫£m", "h·ªçc b·ªïng"

2. NG√ÄNH H·ªåC - V·ªÅ chuy√™n ng√†nh:
   ‚Ä¢ C√°c ng√†nh h·ªçc, chuy√™n ng√†nh, khoa
   ‚Ä¢ Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o, li√™n th√¥ng
   ‚Ä¢ T·ª´ kh√≥a: "ng√†nh", "chuy√™n ng√†nh", "khoa", "ƒë√†o t·∫°o", "li√™n th√¥ng"

3. QUY CH·∫æ THI - V·ªÅ thi c·ª≠ v√† t·ªët nghi·ªáp:
   ‚Ä¢ Quy ƒë·ªãnh thi, ƒëi·ªÅu ki·ªán thi, l·ªãch thi
   ‚Ä¢ ƒêi·ªÅu ki·ªán t·ªët nghi·ªáp, quy ch·∫ø h·ªçc v·ª•
   ‚Ä¢ T·ª´ kh√≥a: "thi", "ki·ªÉm tra", "t·ªët nghi·ªáp", "quy ch·∫ø", "ƒëi·ªÅu ki·ªán"

4. ƒêI·ªÇM S·ªê - V·ªÅ ƒëi·ªÉm v√† ƒë√°nh gi√°:
   ‚Ä¢ Thang ƒëi·ªÉm, c√°ch t√≠nh ƒëi·ªÉm, GPA
   ‚Ä¢ X·∫øp lo·∫°i, h·ªçc l·ª±c, ƒëi·ªÉm trung b√¨nh
   ‚Ä¢ T·ª´ kh√≥a: "ƒëi·ªÉm", "GPA", "thang ƒëi·ªÉm", "x·∫øp lo·∫°i", "h·ªçc l·ª±c"

5. D·ªäCH V·ª§ SINH VI√äN - V·ªÅ th·ªß t·ª•c v√† h·ªó tr·ª£:
   ‚Ä¢ Th·ªß t·ª•c h√†nh ch√≠nh, ƒëƒÉng k√Ω h·ªçc ph·∫ßn
   ‚Ä¢ D·ªãch v·ª• h·ªó tr·ª£, t∆∞ v·∫•n sinh vi√™n
   ‚Ä¢ T·ª´ kh√≥a: "ƒëƒÉng k√Ω", "th·ªß t·ª•c", "h·ªó tr·ª£", "d·ªãch v·ª•", "t∆∞ v·∫•n"

6. C∆† S·ªû V·∫¨T CH·∫§T - V·ªÅ kh√¥ng gian v·∫≠t l√Ω:
   ‚Ä¢ Ph√≤ng h·ªçc, th∆∞ vi·ªán, k√Ω t√∫c x√°
   ‚Ä¢ C∆° s·ªü v·∫≠t ch·∫•t, trang thi·∫øt b·ªã
   ‚Ä¢ T·ª´ kh√≥a: "ph√≤ng", "th∆∞ vi·ªán", "k√Ω t√∫c x√°", "c∆° s·ªü", "trang thi·∫øt b·ªã"

7. CH∆Ø∆†NG TR√åNH H·ªåC - V·ªÅ m√¥n h·ªçc v√† l·ªãch h·ªçc:
   ‚Ä¢ M√¥n h·ªçc, t√≠n ch·ªâ, th·ªùi kh√≥a bi·ªÉu
   ‚Ä¢ L·ªãch h·ªçc, l·ªãch thi, khung ch∆∞∆°ng tr√¨nh
   ‚Ä¢ T·ª´ kh√≥a: "m√¥n h·ªçc", "t√≠n ch·ªâ", "l·ªãch h·ªçc", "th·ªùi kh√≥a bi·ªÉu"

üö´ KH√ÅC - Kh√¥ng li√™n quan gi√°o d·ª•c:
   ‚Ä¢ Th·ªùi ti·∫øt, n·∫•u ƒÉn, th·ªÉ thao, gi·∫£i tr√≠
   ‚Ä¢ Tin t·ª©c, c√¥ng ngh·ªá kh√¥ng li√™n quan h·ªçc t·∫≠p
   ‚Ä¢ C√¢u h·ªèi c√° nh√¢n kh√¥ng v·ªÅ tr∆∞·ªùng h·ªçc

CH·ªà TR·∫¢ V·ªÄ T√äN DANH M·ª§C DUY NH·∫§T - KH√îNG GI·∫¢I TH√çCH G√å TH√äM."""

        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"Ph√¢n lo·∫°i c√¢u h·ªèi: \"{query}\"")
            ]
            
            response = await self.llm.agenerate([messages])
            category = response.generations[0][0].text.strip().upper()
            category = category.replace(".", "").replace(",", "").replace(":", "").strip()
            
            # Validate category
            if category in self.valid_categories:
                result = {
                    "category": category,
                    "is_valid": True,
                    "should_use_vector": True
                }
            else:
                result = {
                    "category": "KH√ÅC",
                    "is_valid": False,
                    "should_use_vector": False
                }
            
            # Cache result
            self.classification_cache[query_hash] = result
            return result
                
        except Exception as e:
            logger.error(f"Error in LLM classification: {e}")
            return {
                "category": "KH√ÅC",
                "is_valid": False,
                "should_use_vector": False,
                "error": str(e)
            }

    async def _vector_search_in_category(self, query: str, category: str) -> Dict:
        """B∆∞·ªõc 3: Vector search trong category partition v·ªõi post-filtering"""
        
        print(f"üîç Vector search in category '{category}' using Qdrant for query: {query[:50]}...")
        
        try:
            # Th·ª±c hi·ªán similarity search s·ª≠ d·ª•ng VectorStore wrapper v·ªõi async method
            results = await self.vector_store.similarity_search_with_score(
                query=query,
                k=50  # L·∫•y nhi·ªÅu results ƒë·ªÉ filter
            )
            
            if not results:
                print(f"‚ùå No results found from Qdrant")
                return {
                    "route": "RAG_CHAT",
                    "reason": f"No similar documents found in vector store",
                    "similarity_score": 0.0,
                    "searched_category": category
                }
            
            # Filter results theo category v·ªõi improved matching
            category_results = []
            found_categories = {}
            
            for doc, similarity in results:
                doc_category = doc.metadata.get('category', '').strip().upper()
                
                # Track t·∫•t c·∫£ categories ƒë·ªÉ debug
                if doc_category in found_categories:
                    found_categories[doc_category] += 1
                else:
                    found_categories[doc_category] = 1
                
                # Improved category matching
                if doc_category == category or \
                   doc_category.replace(' ', '') == category.replace(' ', '') or \
                   (doc_category and category and doc_category in category) or \
                   (doc_category and category and category in doc_category):
                    category_results.append((doc, similarity))
            
            print(f"üìä Categories found in Qdrant results: {found_categories}")
            
            if not category_results:
                print(f"‚ùå No results found in category '{category}' after filtering")
                print(f"üìä Total results from Qdrant: {len(results)}")
                print(f"üîç Available categories: {list(found_categories.keys())}")
                
                # Try fuzzy matching with available categories
                best_match_category = None
                for available_cat in found_categories.keys():
                    if available_cat and category:
                        # Simple fuzzy matching
                        if category.replace(' ', '').lower() in available_cat.replace(' ', '').lower() or \
                           available_cat.replace(' ', '').lower() in category.replace(' ', '').lower():
                            best_match_category = available_cat
                            break
                
                if best_match_category:
                    print(f"ÔøΩ Trying fuzzy match with category '{best_match_category}'")
                    for doc, similarity in results:
                        doc_category = doc.metadata.get('category', '').strip().upper()
                        if doc_category == best_match_category:
                            category_results.append((doc, similarity))
                
                if not category_results:
                    return {
                        "route": "RAG_CHAT",
                        "reason": f"No documents found in category '{category}' (found {len(results)} total results in categories: {list(found_categories.keys())})",
                        "similarity_score": 0.0,
                        "searched_category": category,
                        "available_categories": list(found_categories.keys())
                    }
            
            # Sort filtered results by similarity
            category_results.sort(key=lambda x: x[1], reverse=True)
            
            # L·∫•y k·∫øt qu·∫£ t·ªët nh·∫•t trong category
            best_doc, best_similarity = category_results[0]
            
            print(f"üìä Found {len(category_results)} results in category '{category}'")
            print(f"üìä Best similarity in category '{category}': {best_similarity:.3f}")
            print(f"üîç Best match: {best_doc.page_content[:50]}...")
            
            # Quy·∫øt ƒë·ªãnh d·ª±a tr√™n threshold
            if best_similarity >= self.similarity_threshold:
                print(f"‚úÖ Found good match in category '{category}' (similarity: {best_similarity:.3f} >= {self.similarity_threshold})")
                
                # Extract metadata
                metadata = best_doc.metadata
                answer = metadata.get('answer', '')
                source = metadata.get('source', '')
                matched_question = best_doc.page_content
                
                return {
                    "route": "VECTOR_BASED",
                    "similarity_score": best_similarity,
                    "matched_question": matched_question,
                    "answer": answer,
                    "source": source,
                    "matched_category": category,
                    "all_matches": [
                        {
                            "question": doc.page_content,
                            "similarity": sim,
                            "answer": doc.metadata.get('answer', '')[:100] + "..." if len(doc.metadata.get('answer', '')) > 100 else doc.metadata.get('answer', ''),
                            "category": category
                        }
                        for doc, sim in category_results[:5]  # Top 5 in category
                    ]
                }
            else:
                print(f"‚ùå Similarity too low in category '{category}' (best: {best_similarity:.3f} < {self.similarity_threshold})")
                
                return {
                    "route": "RAG_CHAT",
                    "reason": f"Best similarity {best_similarity:.3f} in category '{category}' below threshold {self.similarity_threshold}",
                    "similarity_score": best_similarity,
                    "searched_category": category,
                    "best_match": {
                        "question": best_doc.page_content,
                        "similarity": best_similarity,
                        "answer": best_doc.metadata.get('answer', '')[:100] + "..." if len(best_doc.metadata.get('answer', '')) > 100 else best_doc.metadata.get('answer', ''),
                        "category": category
                    }
                }
                
        except Exception as e:
            logger.error(f"Error in Qdrant search for category {category}: {e}")
            print(f"‚ùå Error in Qdrant search for category '{category}': {e}")
            return {
                "route": "RAG_CHAT",
                "reason": f"Error during Qdrant search in category {category}: {str(e)}",
                "similarity_score": 0.0,
                "searched_category": category
            }

    async def route_query(self, query: str) -> Dict:
        """Main routing function v·ªõi category-partitioned approach"""
        try:
            print(f"\nüöÄ Category-partitioned routing for query: {query[:50]}...")
            
            # B∆∞·ªõc 1: LLM Classification
            classification_result = await self._classify_query_category(query)
            category = classification_result["category"]
            should_use_vector = classification_result["should_use_vector"]
            
            # B∆∞·ªõc 2: Quy·∫øt ƒë·ªãnh lu·ªìng d·ª±a tr√™n category
            if not should_use_vector or category == "KH√ÅC":
                print(f"‚ö° Category '{category}' ‚Üí Skip vector search ‚Üí Direct RAG_CHAT")
                return {
                    "route": "RAG_CHAT",
                    "reason": f"Category '{category}' requires full RAG processing",
                    "query": query,
                    "classification": classification_result,
                    "similarity_score": 0.0
                }
            
            # B∆∞·ªõc 3: Vector Search trong category partition c·ª• th·ªÉ
            print(f"üéØ Category '{category}' ‚Üí Search in category partition...")
            vector_result = await self._vector_search_in_category(query, category)
            
            # Th√™m th√¥ng tin classification v√†o k·∫øt qu·∫£
            vector_result["query"] = query
            vector_result["classification"] = classification_result
            
            return vector_result
            
        except Exception as e:
            logger.error(f"Error in category-partitioned routing: {e}")
            print(f"‚ùå Error in category-partitioned routing: {e}")
            return {
                "route": "RAG_CHAT",
                "reason": f"Error during routing: {str(e)}",
                "query": query,
                "similarity_score": 0.0
            }

    async def test_query(self, query: str, show_details: bool = True) -> Dict:
        """Test m·ªôt c√¢u h·ªèi v·ªõi category-partitioned approach s·ª≠ d·ª•ng Qdrant"""
        
        print(f"\nüß™ Testing category-partitioned routing (Qdrant) for: '{query}'")
        
        # Test classification
        print(f"\nüìã Step 1: LLM Classification")
        classification_result = await self._classify_query_category(query)
        category = classification_result['category']
        print(f"   Category: {category}")
        print(f"   Should use vector: {classification_result['should_use_vector']}")
        
        if classification_result['should_use_vector'] and category != "KH√ÅC":
            print(f"\nüîç Step 2: Category-Filtered Qdrant Search")
            
            try:
                # Test query Qdrant s·ª≠ d·ª•ng VectorStore wrapper
                results = await self.vector_store.similarity_search_with_score(
                    query=query,
                    k=1
                )
                
                # Filter by category
                category_results = []
                for doc, sim in results:
                    if doc.metadata.get('category', '').strip().upper() == category:
                        category_results.append((doc, sim))
                
                print(f"   üìä Found {len(category_results)} results in category '{category}' from Qdrant (total: {len(results)})")
                
                if show_details and category_results:
                    print(f"\nüìä Top {min(5, len(category_results))} similar questions in category '{category}':")
                    for i, (doc, similarity) in enumerate(category_results[:5], 1):
                        print(f"  {i}. Similarity: {similarity:.3f}")
                        print(f"     Question: {doc.page_content}")
                        answer = doc.metadata.get('answer', '')
                        print(f"     Answer: {answer[:100]}...")
                        print()
            except Exception as e:
                print(f"   ‚ùå Error querying Qdrant: {e}")
        else:
            print(f"\n‚ö° Step 2: Skipped vector search (Category: {category})")
        
        # Get final routing result
        print(f"\nüéØ Final Routing Result:")
        result = await self.route_query(query)
        
        print(f"   Route: {result['route']}")
        if result['route'] == "VECTOR_BASED":
            print(f"   ‚úÖ Matched answer: {result['answer'][:150]}...")
            print(f"   üìä Similarity: {result['similarity_score']:.3f}")
            print(f"   üè∑Ô∏è  Matched in category: {result.get('matched_category', 'N/A')}")
        else:
            print(f"   ‚ùå Reason: {result['reason']}")
        
        return result

    def get_stats(self):
        """Tr·∫£ v·ªÅ th·ªëng k√™ v·ªÅ router performance v√† cache"""
        stats = {
            "vector_store_type": "Qdrant (CategoryPartitioned)",
            "total_questions": len(self.data) if hasattr(self, 'data') and self.data is not None else 0,
            "similarity_threshold": self.similarity_threshold,
            "valid_categories": self.valid_categories.copy(),
            "classification_cache_size": len(self.classification_cache),
            "vector_search_cache_size": len(self.vector_search_cache),
            "categorized_data_loaded": self.use_categorized_data
        }
        
        # Th·ªëng k√™ category t·ª´ data n·∫øu c√≥
        if hasattr(self, 'data') and self.data is not None and 'category' in self.data.columns:
            category_stats = self.data['category'].value_counts().to_dict()
            stats["category_breakdown"] = category_stats
        else:
            stats["category_breakdown"] = {}
        
        # Th·ªëng k√™ cache theo category
        cache_by_category = {}
        for cached_result in self.classification_cache.values():
            category = cached_result.get('category', 'Unknown')
            cache_by_category[category] = cache_by_category.get(category, 0) + 1
        
        stats["classification_cache_by_category"] = cache_by_category
        
        return stats

    async def debug_vector_store_categories(self, sample_size=10):
        """Debug method ƒë·ªÉ ki·ªÉm tra category trong Qdrant"""
        print(f"\nüîç Debugging Qdrant vector store categories...")
        
        try:
            # L·∫•y sample documents t·ª´ Qdrant s·ª≠ d·ª•ng VectorStore wrapper
            results = await self.vector_store.similarity_search_with_score(
                query="test query",
                k=sample_size
            )
            
            print(f"üìä Found {len(results)} documents in Qdrant:")
            
            categories_found = {}
            for i, (doc, score) in enumerate(results):
                metadata = doc.metadata
                category = metadata.get('category', 'NO_CATEGORY')
                source = metadata.get('source', 'NO_SOURCE') 
                
                print(f"  {i+1}. Category: '{category}' | Source: '{source}'")
                print(f"     Content: {doc.page_content[:50]}...")
                print(f"     Metadata keys: {list(metadata.keys())}")
                
                if category in categories_found:
                    categories_found[category] += 1
                else:
                    categories_found[category] = 1
            
            print(f"\nüìã Category Summary in Qdrant:")
            for category, count in categories_found.items():
                print(f"   '{category}': {count} documents")
                
            return categories_found
            
        except Exception as e:
            print(f"‚ùå Error debugging vector store: {e}")
            return {}

    async def analyze_text_format_issue(self):
        """Ph√¢n t√≠ch v·∫•n ƒë·ªÅ format text gi·ªØa cache v√† Qdrant"""
        print(f"\nüîç Analyzing Text Format Issues...")
        
        try:
            # L·∫•y sample documents t·ª´ Qdrant s·ª≠ d·ª•ng VectorStore wrapper
            sample_results = await self.vector_store.similarity_search_with_score(
                query="test query",
                k=5
            )
            
            print(f"üìä Sample document formats in Qdrant:")
            for i, (doc, score) in enumerate(sample_results):
                print(f"\n  Document {i+1}:")
                print(f"    Score: {score:.4f}")
                print(f"    Category: '{doc.metadata.get('category', 'NO_CATEGORY')}'")
                print(f"    Content length: {len(doc.page_content)} characters")
                print(f"    Content format:")
                
                # Show first 200 chars with format analysis
                content_preview = doc.page_content[:200]
                print(f"    '{content_preview}...'")
                
                # Analyze format
                if content_preview.startswith("Question:"):
                    print(f"    ‚úÖ Format: Question-Answer format")
                    
                    # Extract just the question part
                    try:
                        lines = doc.page_content.split('\n')
                        question_line = lines[0].replace("Question: ", "").strip()
                        answer_line = lines[1].replace("Answer: ", "").strip() if len(lines) > 1 else ""
                        
                        print(f"    üìù Extracted Question: '{question_line[:100]}...'")
                        print(f"    üí¨ Extracted Answer: '{answer_line[:100]}...'")
                        
                    except Exception as e:
                        print(f"    ‚ùå Error parsing Q&A format: {e}")
                else:
                    print(f"    ‚ö†Ô∏è  Format: Unknown format")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error analyzing text format: {e}")
            return False
