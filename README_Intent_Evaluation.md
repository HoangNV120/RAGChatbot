# ğŸ“Š ÄÃ¡nh GiÃ¡ Hiá»‡u Quáº£ PhÃ¢n Loáº¡i Ã Äá»‹nh Vá»›i LLM Trong Há»‡ Thá»‘ng Äiá»u Phá»‘i

## ğŸ¯ Tá»•ng Quan

Bá»™ cÃ´ng cá»¥ Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n hiá»‡u quáº£ cá»§a phÃ¢n loáº¡i Ã½ Ä‘á»‹nh sá»­ dá»¥ng LLM trong há»‡ thá»‘ng Ä‘iá»u phá»‘i RAG Chatbot. Há»‡ thá»‘ng nÃ y Ä‘o lÆ°á»ng Ä‘á»™ chÃ­nh xÃ¡c phÃ¢n loáº¡i truy váº¥n vÃ o **8 nhÃ³m chá»§ Ä‘á» chÃ­nh + "KHÃC"** vÃ  phÃ¢n tÃ­ch tÃ¡c Ä‘á»™ng trá»±c tiáº¿p lÃªn hiá»‡u quáº£ pipeline tá»•ng thá»ƒ.

### ğŸ·ï¸ 8 Categories ÄÆ°á»£c ÄÃ¡nh GiÃ¡

1. **Há»ŒC PHÃ** - Chi phÃ­ há»c táº­p, miá»…n giáº£m, há»c bá»•ng
2. **NGÃ€NH Há»ŒC** - ChuyÃªn ngÃ nh, chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o
3. **QUY CHáº¾ THI** - Quy Ä‘á»‹nh thi cá»­, Ä‘iá»u kiá»‡n thi
4. **ÄIá»‚M Sá»** - Thang Ä‘iá»ƒm, GPA, xáº¿p loáº¡i
5. **Dá»ŠCH Vá»¤ SINH VIÃŠN** - Thá»§ tá»¥c, há»— trá»£, tÆ° váº¥n
6. **CÆ  Sá» Váº¬T CHáº¤T** - PhÃ²ng há»c, thÆ° viá»‡n, cÆ¡ sá»Ÿ
7. **CHÆ¯Æ NG TRÃŒNH Há»ŒC** - MÃ´n há»c, lá»‹ch há»c, tÃ­n chá»‰
8. **KHÃC** - CÃ¡c chá»§ Ä‘á» khÃ´ng thuá»™c 7 nhÃ³m trÃªn

## ğŸ“ Cáº¥u TrÃºc Files

```
ğŸ“‚ RAGChatbot/
â”œâ”€â”€ ğŸ“Š evaluate_intent_classification.py     # Module Ä‘Ã¡nh giÃ¡ chÃ­nh
â”œâ”€â”€ ğŸ”¬ advanced_intent_analysis.py           # PhÃ¢n tÃ­ch chuyÃªn sÃ¢u
â”œâ”€â”€ ğŸ“‹ intent_classification_detailed_report.py  # BÃ¡o cÃ¡o chi tiáº¿t
â”œâ”€â”€ ğŸš€ run_intent_evaluation.py              # Script cháº¡y tá»•ng thá»ƒ
â”œâ”€â”€ ğŸ“– README_Intent_Evaluation.md           # HÆ°á»›ng dáº«n nÃ y
â””â”€â”€ ğŸ“ evaluation_results/                   # ThÆ° má»¥c káº¿t quáº£
    â”œâ”€â”€ ğŸ“ˆ intent_classification_analysis_*.png
    â”œâ”€â”€ ğŸ›¤ï¸ routing_effectiveness_analysis_*.png  
    â”œâ”€â”€ ğŸ“„ intent_classification_report_*.json
    â””â”€â”€ ğŸ“ executive_summary_*.txt
```

## ğŸš€ CÃ¡ch Sá»­ Dá»¥ng

### YÃªu Cáº§u TiÃªn Quyáº¿t

```bash
# Äáº£m báº£o cÃ³ file test data
testcase.xlsx  # Chá»©a cá»™t 'question' vá»›i cÃ¡c cÃ¢u há»i test

# Router modules cáº§n thiáº¿t
app/category_partitioned_router.py
app/hybrid_router.py
app/category_router.py
app/vector_store.py
app/config.py
```

### 1. ğŸ¯ Cháº¡y ÄÃ¡nh GiÃ¡ CÆ¡ Báº£n

```python
# Cháº¡y evaluation cÆ¡ báº£n cho táº¥t cáº£ routers
python run_intent_evaluation.py
```

**Káº¿t quáº£:**
- ğŸ“Š Accuracy comparison giá»¯a cÃ¡c routers
- â±ï¸ Thá»i gian phÃ¢n loáº¡i trung bÃ¬nh
- ğŸ¯ Confusion matrix
- ğŸ“ˆ F1-score theo tá»«ng category

### 2. ğŸ“‹ Táº¡o BÃ¡o CÃ¡o Chi Tiáº¿t

```python
# Táº¡o bÃ¡o cÃ¡o chuyÃªn sÃ¢u vá»›i insights
python intent_classification_detailed_report.py
```

**Káº¿t quáº£:**
- ğŸ” Metrics chi tiáº¿t cho tá»«ng category
- ğŸ“Š Precision, Recall, F1-score
- ğŸ”„ PhÃ¢n tÃ­ch tÃ¡c Ä‘á»™ng lÃªn routing pipeline
- ğŸ’¡ Recommendations cá»¥ thá»ƒ

### 3. ğŸ”¬ PhÃ¢n TÃ­ch ChuyÃªn SÃ¢u (TÃ¹y Chá»n)

```python
# PhÃ¢n tÃ­ch error patterns vÃ  optimization opportunities
from advanced_intent_analysis import AdvancedIntentAnalyzer

# Sá»­ dá»¥ng sau khi cÃ³ káº¿t quáº£ tá»« bÆ°á»›c 1 hoáº·c 2
analyzer = AdvancedIntentAnalyzer(evaluation_results)
await analyzer.run_advanced_analysis(classification_results, routing_results)
```

## ğŸ“Š Hiá»ƒu Káº¿t Quáº£ ÄÃ¡nh GiÃ¡

### Overall Metrics

```json
{
  "accuracy": 0.947,           // Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ (94.7%)
  "avg_time_ms": 285,          // Thá»i gian phÃ¢n loáº¡i trung bÃ¬nh
  "total_questions": 500       // Tá»•ng sá»‘ cÃ¢u há»i test
}
```

### Category Performance

```json
{
  "Há»ŒC PHÃ": {
    "precision": 0.95,         // Äá»™ chÃ­nh xÃ¡c dá»± Ä‘oÃ¡n
    "recall": 0.92,            // Tá»· lá»‡ tÃ¬m Ä‘Ãºng
    "f1_score": 0.935,         // Äiá»ƒm F1 tá»•ng há»£p
    "support": 45              // Sá»‘ cÃ¢u há»i trong category
  }
}
```

### Impact Analysis

- **ğŸ¯ Classification Accuracy â†’ Routing Quality**: Äá»™ chÃ­nh xÃ¡c phÃ¢n loáº¡i trá»±c tiáº¿p áº£nh hÆ°á»Ÿng Ä‘áº¿n viá»‡c Ä‘á»‹nh tuyáº¿n
- **âš¡ Response Time**: Thá»i gian phÃ¢n loáº¡i áº£nh hÆ°á»Ÿng Ä‘áº¿n thá»i gian pháº£n há»“i tá»•ng thá»ƒ
- **ğŸ”„ Error Propagation**: Lá»—i phÃ¢n loáº¡i dáº«n Ä‘áº¿n routing sai vÃ  tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng kÃ©m

## ğŸ“ˆ Visualizations & SÆ¡ Äá»“ ÄÆ°á»£c Äá» Xuáº¥t

### ğŸ¯ **Dá»±a TrÃªn Káº¿t Quáº£ Test (87.5% Accuracy, 785ms)**

#### **1. Core Performance Metrics Charts**
```python
# ğŸ“Š Overall Performance Dashboard
â”œâ”€â”€ Accuracy Gauge Chart (87.5% - Good level)
â”œâ”€â”€ Speed Performance Bar (785ms vs 500ms target)
â”œâ”€â”€ Success Rate by Category (Horizontal bar chart)
â””â”€â”€ Performance Rating Visual (Good/Excellent/Needs Improvement)
```

#### **2. Category-Specific Analysis**
```python
# ğŸ·ï¸ 8-Category Performance Breakdown
â”œâ”€â”€ Category Accuracy Heatmap
â”‚   â”œâ”€â”€ QUY CHáº¾ THI: 100% âœ…
â”‚   â”œâ”€â”€ ÄIá»‚M Sá»: 100% âœ…  
â”‚   â”œâ”€â”€ Dá»ŠCH Vá»¤ SINH VIÃŠN: 100% âœ…
â”‚   â”œâ”€â”€ Há»ŒC PHÃ: ~75% (need improvement)
â”‚   â”œâ”€â”€ NGÃ€NH Há»ŒC: ~75% (need improvement)
â”‚   â”œâ”€â”€ CÆ  Sá» Váº¬T CHáº¤T: ~80% (moderate)
â”‚   â”œâ”€â”€ CHÆ¯Æ NG TRÃŒNH Há»ŒC: ~75% (need improvement)
â”‚   â””â”€â”€ KHÃC: ~60% (attention required)
â”œâ”€â”€ Precision-Recall Scatter Plot per Category
â”œâ”€â”€ F1-Score Radar Chart (8 categories)
â””â”€â”€ Support vs Accuracy Bubble Chart
```

#### **3. Error Analysis Visualizations**
```python
# âŒ Misclassification Analysis (4/32 errors)
â”œâ”€â”€ Confusion Matrix (8x8 heatmap)
â”œâ”€â”€ Most Confused Category Pairs
â”œâ”€â”€ Error Distribution by Question Length
â”œâ”€â”€ Keyword Coverage Analysis
â””â”€â”€ Misclassified Questions Detail Table
```

#### **4. Performance vs Speed Trade-off**
```python
# âš¡ Speed-Accuracy Analysis
â”œâ”€â”€ Speed Distribution Histogram (785ms average)
â”œâ”€â”€ Speed vs Accuracy Scatter Plot
â”œâ”€â”€ Percentile Performance Chart (95th percentile)
â””â”€â”€ Time Budget Allocation (Pie chart)
    â”œâ”€â”€ Classification: ~400ms
    â”œâ”€â”€ Vector Search: ~250ms
    â”œâ”€â”€ LLM Processing: ~135ms
```

#### **5. Pipeline Impact Visualization**
```python
# ğŸ”„ Routing Effectiveness
â”œâ”€â”€ Pipeline Flow Diagram
â”‚   â”œâ”€â”€ 87.5% â†’ Correct Route â†’ Good Response
â”‚   â”œâ”€â”€ 12.5% â†’ Wrong Route â†’ Poor Response
â”œâ”€â”€ User Experience Impact Chart
â”œâ”€â”€ Response Quality Prediction
â””â”€â”€ Business Metrics Impact
```

### ğŸ¨ **Recommended Charts Ä‘á»ƒ Váº½**

#### **Chart 1: Performance Overview Dashboard**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¯ INTENT CLASSIFICATION PERFORMANCE OVERVIEW         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Overall Accuracy: 87.5% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œâ–‘  [Good]           â”‚
â”‚  Average Speed: 785ms     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘  [Needs Work]     â”‚
â”‚  Categories: 8/8 working  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [Excellent]      â”‚
â”‚  Error Rate: 12.5%        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œâ–‘  [Acceptable]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **Chart 2: Category Performance Matrix**
```
                     Accuracy  Speed   Priority
QUY CHáº¾ THI         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ    âœ… Maintain
ÄIá»‚M Sá»             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ    âœ… Maintain  
Dá»ŠCH Vá»¤ SINH VIÃŠN   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆ     âœ… Maintain
CÆ  Sá» Váº¬T CHáº¤T      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ     ğŸŸ¡ Monitor
Há»ŒC PHÃ             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ     ğŸŸ¡ Improve
NGÃ€NH Há»ŒC           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆ      ğŸ”´ Focus
CHÆ¯Æ NG TRÃŒNH Há»ŒC    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â–ˆâ–ˆ      ğŸ”´ Focus
KHÃC                â–ˆâ–ˆâ–ˆâ–ˆ      â–ˆâ–ˆ      ï¿½ Redesign
```

#### **Chart 3: Confusion Matrix Heatmap**
```
Predicted â†’  Há»ŒC  NGÃ€NH QUY  ÄIá»‚M Dá»ŠCH  CÆ    CHÆ¯Æ NG KHÃC
Actual â†“     PHÃ  Há»ŒC   CHáº¾  Sá»   Vá»¤    Sá»   TRÃŒNH    
Há»ŒC PHÃ       3    0    0    1    0     0     0      0
NGÃ€NH Há»ŒC     0    3    0    0    0     0     1      0  
QUY CHáº¾ THI   0    0    4    0    0     0     0      0
ÄIá»‚M Sá»       0    0    0    4    0     0     0      0
Dá»ŠCH Vá»¤ SV    0    0    0    0    2     0     0      0
CÆ  Sá» Váº¬T CHáº¤T 0   0    0    0    0     4     0      1
CHÆ¯Æ NG TRÃŒNH  0    1    0    0    0     0     3      0
KHÃC          0    0    0    0    0     1     0      4
```

#### **Chart 4: Speed vs Accuracy Optimization**
```
Speed (ms)
    â”‚
1000â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â—CURRENT (785ms, 87.5%)
    â”‚         â”‚
 800â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
 600â”œâ”€â”€â”€â”€â”€â”€â”€TARGET ZONE (500ms, 90%+)
    â”‚       â”Œâ”€â”€â”€â”€â”€â—TARGET
 400â”œâ”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
 200â”œâ”€IDEAL (200ms, 95%+)
    â”‚
   0â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Accuracy (%)
    70   75   80   85   90   95   100
```

### ğŸ“Š **Implementation Code cho Charts**

#### **Code Snippet: Táº¡o Performance Dashboard**
```python
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def create_performance_dashboard(results):
    """Táº¡o dashboard tá»•ng quan hiá»‡u suáº¥t"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('ï¿½ Intent Classification Performance Dashboard', fontsize=16)
    
    # 1. Accuracy Gauge
    accuracy = results['accuracy']  # 0.875
    colors = ['red' if accuracy < 0.8 else 'orange' if accuracy < 0.9 else 'green']
    
    # Gauge chart for accuracy
    theta = np.linspace(0, np.pi, 100)
    r = np.ones(100)
    ax1.plot(theta, r, 'k-', linewidth=2)
    ax1.fill_between(theta, 0, r, alpha=0.3, color=colors[0])
    ax1.set_title(f'Overall Accuracy: {accuracy:.1%}')
    ax1.set_ylim(0, 1.2)
    
    # 2. Speed Performance  
    categories = ['QUY CHáº¾ THI', 'ÄIá»‚M Sá»', 'Dá»ŠCH Vá»¤ SV', 'CÆ  Sá» Váº¬T CHáº¤T', 
                 'Há»ŒC PHÃ', 'NGÃ€NH Há»ŒC', 'CHÆ¯Æ NG TRÃŒNH', 'KHÃC']
    accuracies = [1.0, 1.0, 1.0, 0.8, 0.75, 0.75, 0.75, 0.6]  # Based on results
    
    bars = ax2.barh(categories, accuracies, color=['green' if x >= 0.9 else 'orange' if x >= 0.8 else 'red' for x in accuracies])
    ax2.set_title('Category Performance')
    ax2.set_xlim(0, 1)
    
    # 3. Confusion Matrix
    confusion_data = np.array([
        [3, 0, 0, 1, 0, 0, 0, 0],  # Há»ŒC PHÃ
        [0, 3, 0, 0, 0, 0, 1, 0],  # NGÃ€NH Há»ŒC  
        [0, 0, 4, 0, 0, 0, 0, 0],  # QUY CHáº¾ THI
        [0, 0, 0, 4, 0, 0, 0, 0],  # ÄIá»‚M Sá»
        [0, 0, 0, 0, 2, 0, 0, 0],  # Dá»ŠCH Vá»¤ SV
        [0, 0, 0, 0, 0, 4, 0, 1],  # CÆ  Sá» Váº¬T CHáº¤T
        [0, 1, 0, 0, 0, 0, 3, 0],  # CHÆ¯Æ NG TRÃŒNH
        [0, 0, 0, 0, 0, 1, 0, 4],  # KHÃC
    ])
    
    sns.heatmap(confusion_data, annot=True, fmt='d', cmap='Blues', 
                xticklabels=categories, yticklabels=categories, ax=ax3)
    ax3.set_title('Confusion Matrix')
    
    # 4. Speed vs Target
    current_speed = 785  # ms
    target_speed = 500   # ms
    
    ax4.bar(['Current', 'Target'], [current_speed, target_speed], 
            color=['red', 'green'])
    ax4.set_title('Speed Performance (ms)')
    ax4.set_ylabel('Time (ms)')
    
    plt.tight_layout()
    plt.savefig('evaluation_results/performance_dashboard.png', dpi=300, bbox_inches='tight')
    plt.show()

# Usage
results = {
    'accuracy': 0.875,
    'avg_time_ms': 785,
    'category_performance': {...}  # From your test results
}

create_performance_dashboard(results)
```

### ï¿½ **Priority Visualizations (LÃ m TrÆ°á»›c)**

1. **ğŸ“Š Performance Dashboard** - Overview tá»•ng quan
2. **ğŸ¯ Category Accuracy Chart** - Identify problem categories  
3. **â±ï¸ Speed Analysis** - Optimize performance bottlenecks
4. **ğŸ”„ Confusion Matrix** - Fix misclassification patterns
5. **ï¿½ Improvement Roadmap** - Action plan visualization

### ğŸ’¡ **Key Insights Ä‘á»ƒ Highlight**

- **87.5% accuracy** = Good starting point
- **3 perfect categories** = Strong foundation  
- **785ms speed** = Primary optimization target
- **12.5% error rate** = Manageable improvement scope
- **Balanced test data** = Reliable evaluation results

## ğŸ’¡ Insights ChÃ­nh

### ğŸ¯ Accuracy Benchmarks
- **Excellent**: >95% accuracy
- **Good**: 85-95% accuracy  
- **Needs Improvement**: <85% accuracy

### â±ï¸ Performance Benchmarks
- **Fast**: <200ms per classification
- **Acceptable**: 200-500ms
- **Slow**: >500ms

### ğŸ”„ Pipeline Impact
- **High Accuracy (>90%)**: Positive impact on routing effectiveness
- **Medium Accuracy (80-90%)**: Moderate impact, optimization needed
- **Low Accuracy (<80%)**: Negative impact, immediate action required

## ğŸ› ï¸ Optimization Recommendations

### Immediate Actions (Náº¿u Accuracy < 90%)
1. **ğŸ¯ Prompt Engineering**: Cáº£i thiá»‡n prompts cho categories hay bá»‹ nháº§m láº«n
2. **ğŸ“ Add Examples**: ThÃªm few-shot examples vÃ o prompts
3. **ğŸ” Keyword Pre-filtering**: Implement rule-based pre-classification

### Medium Term Improvements
1. **âš¡ Caching**: Cache káº¿t quáº£ cho cÃ¢u há»i tÆ°Æ¡ng tá»±
2. **ğŸ¤– Model Optimization**: Fine-tune model cho domain cá»¥ thá»ƒ
3. **ğŸ“Š Confidence Scoring**: ThÃªm confidence score cho fallback logic

### Long Term Optimizations
1. **ğŸ”„ Ensemble Methods**: Káº¿t há»£p multiple classification approaches
2. **ğŸ“ˆ Active Learning**: Continuous learning tá»« production data
3. **âš–ï¸ Speed vs Accuracy Trade-off**: Optimize dá»±a trÃªn requirements

## ğŸ“ TÃ¹y Chá»‰nh Evaluation

### Thay Äá»•i Test Data
```python
# Sá»­ dá»¥ng file test data khÃ¡c
evaluator = IntentClassificationEvaluator(test_data_path="custom_test.xlsx")
```

### ThÃªm Categories Má»›i
```python
# Trong evaluate_intent_classification.py
self.categories = [
    "Há»ŒC PHÃ", "NGÃ€NH Há»ŒC", "QUY CHáº¾ THI", "ÄIá»‚M Sá»", 
    "Dá»ŠCH Vá»¤ SINH VIÃŠN", "CÆ  Sá» Váº¬T CHáº¤T", "CHÆ¯Æ NG TRÃŒNH Há»ŒC",
    "CATEGORY_Má»šI",  # ThÃªm category má»›i
    "KHÃC"
]
```

### Äiá»u Chá»‰nh Thresholds
```python
# Trong router configuration
self.similarity_threshold = 0.8  # Äiá»u chá»‰nh threshold
self.classification_timeout = 30  # Timeout cho classification
```

## ğŸ”§ Troubleshooting

### Lá»—i ThÆ°á»ng Gáº·p

**1. ImportError: No module named 'app.router'**
```bash
# Äáº£m báº£o structure thÆ° má»¥c Ä‘Ãºng vÃ  cÃ³ __init__.py files
```

**2. FileNotFoundError: testcase.xlsx**
```bash
# Táº¡o file testcase.xlsx vá»›i cá»™t 'question'
# Hoáº·c specify path khÃ¡c trong constructor
```

**3. Router Initialization Failed**
```bash
# Kiá»ƒm tra vector_store vÃ  config.py
# Äáº£m báº£o OpenAI API key Ä‘Æ°á»£c set
```

### Debug Mode
```python
# Báº­t debug logging
import logging
logging.basicConfig(level=logging.DEBUG)

# Cháº¡y vá»›i má»™t sá»‘ lÆ°á»£ng nhá» cÃ¢u há»i Ä‘á»ƒ test
test_subset = test_data.head(10)
```

## ğŸ“ Há»— Trá»£

- ğŸ“§ **Issues**: Táº¡o issue trong repository
- ğŸ“– **Documentation**: Xem README_Research_Methodology.md
- ğŸ”¬ **Advanced Usage**: Xem source code comments

## ğŸ“… Version History

- **v1.0** (2025-07-27): Initial release vá»›i comprehensive evaluation
- **v1.1** (Planned): ThÃªm real-time monitoring capabilities
- **v1.2** (Planned): Integration vá»›i MLflow cho experiment tracking

---

ğŸ’¡ **Tip**: Cháº¡y evaluation Ä‘á»‹nh ká»³ Ä‘á»ƒ monitor performance degradation vÃ  detect drift trong classification accuracy.
